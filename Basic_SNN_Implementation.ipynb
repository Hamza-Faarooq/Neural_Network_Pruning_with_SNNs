{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamza-Faarooq/Neural_Network_Pruning_with_SNNs/blob/main/Basic_SNN_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snntorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcCM6vlFQda5",
        "outputId": "61ff7e85-25cf-4e32-b06f-37eca1c2cb60"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting snntorch\n",
            "  Downloading snntorch-0.9.4-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Downloading snntorch-0.9.4-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/125.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: snntorch\n",
            "Successfully installed snntorch-0.9.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "from snntorch import utils\n",
        "from snntorch import functional as SF\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "vXgZ7ysBQVj9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load MNIST\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_data = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_data = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GziZGj3AQccU",
        "outputId": "4ce38eb5-347c-4017-f90f-67c588507909"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.6MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 514kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.89MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.20MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SNN model\n",
        "class SNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 100)\n",
        "        self.lif1 = snn.Leaky(beta=0.9, spike_grad=surrogate.fast_sigmoid())\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        self.lif2 = snn.Leaky(beta=0.9, spike_grad=surrogate.fast_sigmoid())\n",
        "\n",
        "    def forward(self, x, num_steps=25):\n",
        "        mem1, mem2 = self.lif1.init_leaky(), self.lif2.init_leaky()\n",
        "        spk2_rec = []\n",
        "        for step in range(num_steps):\n",
        "            cur1 = self.fc1(x.view(x.size(0), -1))\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "            spk2_rec.append(spk2)\n",
        "\n",
        "        return torch.stack(spk2_rec).sum(0)\n",
        "\n",
        "model = SNN().to(device)\n",
        "loss_fn = SF.mse_count_loss(correct_rate=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "LzP0fjdjQs5F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    for data, targets in train_loader:\n",
        "        data, targets = data.to(device), targets.to(device)\n",
        "        # Remove the one-hot encoding line\n",
        "        # targets_onehot = torch.nn.functional.one_hot(targets, 10).float()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        # Pass the original targets to the loss function\n",
        "        loss = loss_fn(output, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt4H-TImQvI-",
        "outputId": "7f4a0a5c-d213-4183-b707-7da8c86115aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([64, 10])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([32, 10])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.3227\n",
            "Epoch 2, Loss: 2.1719\n",
            "Epoch 3, Loss: 2.2289\n",
            "Epoch 4, Loss: 2.2602\n",
            "Epoch 5, Loss: 2.2273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_weights(model, prune_ratio=0.5):\n",
        "    with torch.no_grad():\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                flat = param.view(-1)\n",
        "                k = int(len(flat) * prune_ratio)\n",
        "                threshold = torch.topk(torch.abs(flat), k, largest=False).values.max()\n",
        "                mask = torch.abs(param) > threshold\n",
        "                param *= mask  # Zero out pruned weights\n",
        "\n",
        "prune_weights(model, prune_ratio=0.5)"
      ],
      "metadata": {
        "id": "NDSfDOQvQy18"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_criticality(model, data_sample):\n",
        "    model.eval()\n",
        "    data_sample = data_sample.to(device)\n",
        "    data_sample.requires_grad = True\n",
        "\n",
        "    output = model(data_sample)\n",
        "    score = output.sum()\n",
        "    score.backward()\n",
        "\n",
        "    criticality = {}\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.grad is not None:\n",
        "            criticality[name] = param.grad.abs().mean().item()\n",
        "    return criticality\n",
        "\n",
        "# Example: Compute criticality from one sample\n",
        "data_sample, _ = next(iter(train_loader))\n",
        "criticality_scores = compute_criticality(model, data_sample[:1])\n",
        "print(criticality_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n4OgLAQRLd3",
        "outputId": "9ada9b19-26e6-4dbf-d763-6ce9d5175e3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fc1.weight': 0.000143510740599595, 'fc1.bias': 0.001367890159599483, 'fc2.weight': 0.3957519233226776, 'fc2.bias': 9.710383415222168}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cvxpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC0k2mWLRcwb",
        "outputId": "38af8348-198e-4643-d3ce-6c61ab0ba39c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.11/dist-packages (1.6.5)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from cvxpy) (1.0.4)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from cvxpy) (0.10.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.11/dist-packages (from cvxpy) (3.2.7.post2)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from cvxpy) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from cvxpy) (1.15.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy) (75.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy) (1.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->osqp>=0.6.2->cvxpy) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cvxpy as cp\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "W = np.random.randn(10)\n",
        "X = np.random.randn(100, 10)\n",
        "Y = X @ W + np.random.randn(100) * 0.1\n",
        "\n",
        "m = cp.Variable(10)  # Continuous mask\n",
        "objective = cp.Minimize(0.5 * cp.sum_squares(cp.multiply(W, m) @ X.T - Y) + 0.1 * cp.norm(m, 1))\n",
        "constraints = [m >= 0, m <= 1, cp.sum(m) <= 6]\n",
        "problem = cp.Problem(objective, constraints)\n",
        "\n",
        "problem.solve(solver=cp.OSQP)\n",
        "print(\"Relaxed pruning mask:\", m.value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9dO19XFROOG",
        "outputId": "450c4eca-c271-4111-cbae-9d9252879b45"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relaxed pruning mask: [ 9.81291267e-01  2.61332984e-01  8.40310495e-01  9.57598391e-01\n",
            "  1.00000000e+00  8.54759885e-01  8.79327296e-01 -1.17099840e-16\n",
            " -1.12465879e-16  2.25379681e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "binary_mask = (m.value > 0.5).astype(int)\n",
        "print(\"Binary pruning mask:\", binary_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJoas9y_RRAY",
        "outputId": "b8765924-50b6-4490-9c97-f0162257b8e1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary pruning mask: [1 0 1 1 1 1 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "soft_mask = np.array([\n",
        "    0.981, 0.261, 0.840, 0.957, 1.0,\n",
        "    0.855, 0.879, -1.17e-16, -1.12e-16, 0.225\n",
        "])\n",
        "\n",
        "threshold = 0.5\n",
        "binary_mask = (soft_mask > threshold).astype(int)\n",
        "print(\"Binary pruning mask:\", binary_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11S5l3F2VGzb",
        "outputId": "3d9d1a38-155b-4d46-9169-ca4044984a51"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary pruning mask: [1 0 1 1 1 1 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# dummy weight vector\n",
        "weights = torch.randn(10)\n",
        "\n",
        "# apply pruning\n",
        "weights *= torch.tensor(binary_mask, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "vTQBy2c9V4I2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = torch.nn.Linear(10, 1)\n",
        "with torch.no_grad():\n",
        "    layer.weight *= torch.tensor(binary_mask, dtype=torch.float32).unsqueeze(0)"
      ],
      "metadata": {
        "id": "qpnI6rXeV8FR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_sparsity(layer):\n",
        "    total = layer.weight.numel()\n",
        "    zeros = torch.sum(layer.weight == 0).item()\n",
        "    return zeros / total\n",
        "\n",
        "print(\"Sparsity:\", compute_sparsity(layer))\n"
      ],
      "metadata": {
        "id": "BOsXsc7nV-0_",
        "outputId": "e7fa9b39-edc2-4d35-97cb-39f8e9e58524",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity: 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2):  # You can increase epochs later\n",
        "    model.train()\n",
        "    for data, targets in train_loader:\n",
        "        data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, targets)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Remove the incorrect pruning application:\n",
        "        # Apply binary pruning mask AFTER weight update\n",
        "        # for name, param in model.named_parameters():\n",
        "        #     if \"fc1.weight\" in name:\n",
        "        #         param.data *= torch.tensor(binary_mask).float().to(param.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XtYZFVXkL8V",
        "outputId": "2ca2ca1d-3a3a-4db0-aa28-1e3103a02cc7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([64, 10])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([32, 10])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPwh+GMdImw8ix6vfxGSYlO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}